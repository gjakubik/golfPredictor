{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Golf Predictor "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (0) Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "# dfRaw is raw dataset read from csv\n",
    "dfRaw = pd.read_csv(\"../data_2015_thru_2019.csv\")\n",
    "dfRaw = dfRaw.drop(['RANK FOLLOWING YEAR'], axis=1) # remove rank following year col\n",
    "dfRaw\n",
    "distance_dict = {\"A\" : 1, \"B\" : 2, \"C\" : 3, \"D\" : 4, \"E\" : 5, \"F\" : 6}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (0.1) Load Training Data from File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# --------- For Now we will be using 2015-2018 as TRAINING, 2019 as TESTING --------------\n",
    "dfTrain = pd.read_csv(\"../training.csv\")\n",
    "# delete rank next year column\n",
    "dfTrain = dfTrain.drop(['RANK FOLLOWING YEAR'], axis=1) # remove rank following year col\n",
    "dfTrain"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER NAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ROUNDS</th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>TOTAL SG:ARG</th>\n",
       "      <th>MEASURED ROUNDS</th>\n",
       "      <th>ROUNDS_x</th>\n",
       "      <th>AVERAGE_x</th>\n",
       "      <th>SG:OTT</th>\n",
       "      <th>SG:APR</th>\n",
       "      <th>SG:ARG</th>\n",
       "      <th>AVERAGE_y</th>\n",
       "      <th>TOTAL SG:T</th>\n",
       "      <th>TOTAL SG:T2G</th>\n",
       "      <th>TOTAL SG:P</th>\n",
       "      <th>AVERAGE_x.1</th>\n",
       "      <th>TOTAL SG:PUTTING</th>\n",
       "      <th>AVERAGE_y.1</th>\n",
       "      <th>TOTAL SG:APP</th>\n",
       "      <th>RANK AS LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason Day</td>\n",
       "      <td>2015</td>\n",
       "      <td>75</td>\n",
       "      <td>0.287</td>\n",
       "      <td>16.357</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>1.520</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.287</td>\n",
       "      <td>2.106</td>\n",
       "      <td>120.054</td>\n",
       "      <td>86.649</td>\n",
       "      <td>33.407</td>\n",
       "      <td>0.586</td>\n",
       "      <td>33.407</td>\n",
       "      <td>0.461</td>\n",
       "      <td>26.260</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dustin Johnson</td>\n",
       "      <td>2015</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-11.466</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>1.455</td>\n",
       "      <td>78.552</td>\n",
       "      <td>71.623</td>\n",
       "      <td>6.932</td>\n",
       "      <td>0.128</td>\n",
       "      <td>6.932</td>\n",
       "      <td>0.579</td>\n",
       "      <td>31.252</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jordan Spieth</td>\n",
       "      <td>2015</td>\n",
       "      <td>91</td>\n",
       "      <td>0.471</td>\n",
       "      <td>31.054</td>\n",
       "      <td>66</td>\n",
       "      <td>91</td>\n",
       "      <td>1.583</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.471</td>\n",
       "      <td>2.154</td>\n",
       "      <td>142.131</td>\n",
       "      <td>104.470</td>\n",
       "      <td>37.665</td>\n",
       "      <td>0.571</td>\n",
       "      <td>37.665</td>\n",
       "      <td>0.618</td>\n",
       "      <td>40.776</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henrik Stenson</td>\n",
       "      <td>2015</td>\n",
       "      <td>63</td>\n",
       "      <td>0.082</td>\n",
       "      <td>3.604</td>\n",
       "      <td>44</td>\n",
       "      <td>63</td>\n",
       "      <td>1.774</td>\n",
       "      <td>0.448</td>\n",
       "      <td>1.244</td>\n",
       "      <td>0.082</td>\n",
       "      <td>2.210</td>\n",
       "      <td>97.245</td>\n",
       "      <td>78.041</td>\n",
       "      <td>19.205</td>\n",
       "      <td>0.436</td>\n",
       "      <td>19.205</td>\n",
       "      <td>1.244</td>\n",
       "      <td>54.732</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Scott</td>\n",
       "      <td>2015</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-6.238</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.206</td>\n",
       "      <td>6.577</td>\n",
       "      <td>19.240</td>\n",
       "      <td>-12.662</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>-12.662</td>\n",
       "      <td>0.114</td>\n",
       "      <td>3.659</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Johnson Wagner</td>\n",
       "      <td>2018</td>\n",
       "      <td>75</td>\n",
       "      <td>0.226</td>\n",
       "      <td>12.456</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.715</td>\n",
       "      <td>39.339</td>\n",
       "      <td>5.049</td>\n",
       "      <td>34.292</td>\n",
       "      <td>0.623</td>\n",
       "      <td>34.292</td>\n",
       "      <td>0.078</td>\n",
       "      <td>4.304</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Scott Brown</td>\n",
       "      <td>2018</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-14.172</td>\n",
       "      <td>81</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>-53.530</td>\n",
       "      <td>-57.498</td>\n",
       "      <td>3.967</td>\n",
       "      <td>0.049</td>\n",
       "      <td>3.967</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-21.856</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Trey Mullinax</td>\n",
       "      <td>2018</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-12.199</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.506</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-4.231</td>\n",
       "      <td>-8.472</td>\n",
       "      <td>4.243</td>\n",
       "      <td>0.072</td>\n",
       "      <td>4.243</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-26.106</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Shawn Stefani</td>\n",
       "      <td>2018</td>\n",
       "      <td>76</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.809</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.107</td>\n",
       "      <td>6.420</td>\n",
       "      <td>8.464</td>\n",
       "      <td>-2.045</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-2.045</td>\n",
       "      <td>0.220</td>\n",
       "      <td>13.227</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Cameron Tringale</td>\n",
       "      <td>2018</td>\n",
       "      <td>67</td>\n",
       "      <td>0.088</td>\n",
       "      <td>4.506</td>\n",
       "      <td>51</td>\n",
       "      <td>67</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-1.351</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-1.019</td>\n",
       "      <td>-51.965</td>\n",
       "      <td>-46.678</td>\n",
       "      <td>-5.287</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-5.287</td>\n",
       "      <td>0.348</td>\n",
       "      <td>17.732</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PLAYER NAME  YEAR  ROUNDS  AVERAGE  TOTAL SG:ARG  MEASURED ROUNDS  \\\n",
       "0           Jason Day  2015      75    0.287        16.357               57   \n",
       "1      Dustin Johnson  2015      75   -0.212       -11.466               54   \n",
       "2       Jordan Spieth  2015      91    0.471        31.054               66   \n",
       "3      Henrik Stenson  2015      63    0.082         3.604               44   \n",
       "4          Adam Scott  2015      51   -0.195        -6.238               32   \n",
       "..                ...   ...     ...      ...           ...              ...   \n",
       "499    Johnson Wagner  2018      75    0.226        12.456               55   \n",
       "500       Scott Brown  2018     102   -0.175       -14.172               81   \n",
       "501     Trey Mullinax  2018      75   -0.207       -12.199               59   \n",
       "502     Shawn Stefani  2018      76    0.013         0.809               60   \n",
       "503  Cameron Tringale  2018      67    0.088         4.506               51   \n",
       "\n",
       "     ROUNDS_x  AVERAGE_x  SG:OTT  SG:APR  SG:ARG  AVERAGE_y  TOTAL SG:T  \\\n",
       "0          75      1.520   0.772   0.461   0.287      2.106     120.054   \n",
       "1          75      1.326   0.960   0.579  -0.212      1.455      78.552   \n",
       "2          91      1.583   0.494   0.618   0.471      2.154     142.131   \n",
       "3          63      1.774   0.448   1.244   0.082      2.210      97.245   \n",
       "4          51      0.601   0.682   0.114  -0.195      0.206       6.577   \n",
       "..        ...        ...     ...     ...     ...        ...         ...   \n",
       "499        75      0.092  -0.213   0.078   0.226      0.715      39.339   \n",
       "500       102     -0.710  -0.265  -0.270  -0.175     -0.661     -53.530   \n",
       "501        75     -0.144   0.506  -0.442  -0.207     -0.072      -4.231   \n",
       "502        76      0.141  -0.093   0.220   0.013      0.107       6.420   \n",
       "503        67     -0.915  -1.351   0.348   0.088     -1.019     -51.965   \n",
       "\n",
       "     TOTAL SG:T2G  TOTAL SG:P  AVERAGE_x.1  TOTAL SG:PUTTING  AVERAGE_y.1  \\\n",
       "0          86.649      33.407        0.586            33.407        0.461   \n",
       "1          71.623       6.932        0.128             6.932        0.579   \n",
       "2         104.470      37.665        0.571            37.665        0.618   \n",
       "3          78.041      19.205        0.436            19.205        1.244   \n",
       "4          19.240     -12.662       -0.396           -12.662        0.114   \n",
       "..            ...         ...          ...               ...          ...   \n",
       "499         5.049      34.292        0.623            34.292        0.078   \n",
       "500       -57.498       3.967        0.049             3.967       -0.270   \n",
       "501        -8.472       4.243        0.072             4.243       -0.442   \n",
       "502         8.464      -2.045       -0.034            -2.045        0.220   \n",
       "503       -46.678      -5.287       -0.104            -5.287        0.348   \n",
       "\n",
       "     TOTAL SG:APP RANK AS LABEL  \n",
       "0          26.260             A  \n",
       "1          31.252             A  \n",
       "2          40.776             A  \n",
       "3          54.732             A  \n",
       "4           3.659             A  \n",
       "..            ...           ...  \n",
       "499         4.304             F  \n",
       "500       -21.856             F  \n",
       "501       -26.106             F  \n",
       "502        13.227             F  \n",
       "503        17.732             F  \n",
       "\n",
       "[504 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (0.2) Load Testing Data from File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dfTest = pd.read_csv(\"../testing.csv\")\n",
    "dfTest = dfTest.drop(\"RANK FOLLOWING YEAR\", axis=1)\n",
    "dfTest"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER NAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ROUNDS</th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>TOTAL SG:ARG</th>\n",
       "      <th>MEASURED ROUNDS</th>\n",
       "      <th>ROUNDS_x</th>\n",
       "      <th>AVERAGE_x</th>\n",
       "      <th>SG:OTT</th>\n",
       "      <th>SG:APR</th>\n",
       "      <th>SG:ARG</th>\n",
       "      <th>AVERAGE_y</th>\n",
       "      <th>TOTAL SG:T</th>\n",
       "      <th>TOTAL SG:T2G</th>\n",
       "      <th>TOTAL SG:P</th>\n",
       "      <th>AVERAGE_x.1</th>\n",
       "      <th>TOTAL SG:PUTTING</th>\n",
       "      <th>AVERAGE_y.1</th>\n",
       "      <th>TOTAL SG:APP</th>\n",
       "      <th>RANK AS LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dustin Johnson</td>\n",
       "      <td>2019</td>\n",
       "      <td>73</td>\n",
       "      <td>0.234</td>\n",
       "      <td>13.098</td>\n",
       "      <td>56</td>\n",
       "      <td>73</td>\n",
       "      <td>1.225</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.234</td>\n",
       "      <td>1.321</td>\n",
       "      <td>73.995</td>\n",
       "      <td>68.619</td>\n",
       "      <td>5.378</td>\n",
       "      <td>0.096</td>\n",
       "      <td>5.378</td>\n",
       "      <td>0.288</td>\n",
       "      <td>16.143</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jon Rahm</td>\n",
       "      <td>2019</td>\n",
       "      <td>75</td>\n",
       "      <td>0.073</td>\n",
       "      <td>3.863</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>1.170</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1.505</td>\n",
       "      <td>79.788</td>\n",
       "      <td>61.994</td>\n",
       "      <td>17.793</td>\n",
       "      <td>0.336</td>\n",
       "      <td>17.793</td>\n",
       "      <td>0.405</td>\n",
       "      <td>21.449</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justin Thomas</td>\n",
       "      <td>2019</td>\n",
       "      <td>75</td>\n",
       "      <td>0.352</td>\n",
       "      <td>19.729</td>\n",
       "      <td>56</td>\n",
       "      <td>75</td>\n",
       "      <td>1.817</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.631</td>\n",
       "      <td>91.314</td>\n",
       "      <td>101.736</td>\n",
       "      <td>-10.419</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-10.419</td>\n",
       "      <td>0.985</td>\n",
       "      <td>55.176</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rory McIlroy</td>\n",
       "      <td>2019</td>\n",
       "      <td>72</td>\n",
       "      <td>0.297</td>\n",
       "      <td>16.939</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>2.126</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.297</td>\n",
       "      <td>2.551</td>\n",
       "      <td>145.379</td>\n",
       "      <td>121.159</td>\n",
       "      <td>24.221</td>\n",
       "      <td>0.425</td>\n",
       "      <td>24.221</td>\n",
       "      <td>0.633</td>\n",
       "      <td>36.096</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Webb Simpson</td>\n",
       "      <td>2019</td>\n",
       "      <td>81</td>\n",
       "      <td>0.294</td>\n",
       "      <td>20.269</td>\n",
       "      <td>69</td>\n",
       "      <td>81</td>\n",
       "      <td>0.899</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.294</td>\n",
       "      <td>1.507</td>\n",
       "      <td>104.007</td>\n",
       "      <td>62.051</td>\n",
       "      <td>41.957</td>\n",
       "      <td>0.608</td>\n",
       "      <td>41.957</td>\n",
       "      <td>0.613</td>\n",
       "      <td>42.285</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Patton Kizzire</td>\n",
       "      <td>2019</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-6.337</td>\n",
       "      <td>53</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-5.192</td>\n",
       "      <td>-39.241</td>\n",
       "      <td>34.050</td>\n",
       "      <td>0.642</td>\n",
       "      <td>34.050</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-6.987</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Peter Malnati</td>\n",
       "      <td>2019</td>\n",
       "      <td>87</td>\n",
       "      <td>0.097</td>\n",
       "      <td>7.362</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.379</td>\n",
       "      <td>28.774</td>\n",
       "      <td>-6.693</td>\n",
       "      <td>35.469</td>\n",
       "      <td>0.467</td>\n",
       "      <td>35.469</td>\n",
       "      <td>0.225</td>\n",
       "      <td>17.084</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Bronson Burgoon</td>\n",
       "      <td>2019</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-3.481</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-16.148</td>\n",
       "      <td>-2.469</td>\n",
       "      <td>-13.679</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>-13.679</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-1.540</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Chris Stroud</td>\n",
       "      <td>2019</td>\n",
       "      <td>70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1.808</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>-0.557</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.729</td>\n",
       "      <td>-37.920</td>\n",
       "      <td>-39.088</td>\n",
       "      <td>1.165</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1.165</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-11.918</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Roberto Díaz</td>\n",
       "      <td>2019</td>\n",
       "      <td>73</td>\n",
       "      <td>0.063</td>\n",
       "      <td>3.190</td>\n",
       "      <td>51</td>\n",
       "      <td>73</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-6.295</td>\n",
       "      <td>-14.533</td>\n",
       "      <td>8.239</td>\n",
       "      <td>0.162</td>\n",
       "      <td>8.239</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>-23.741</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PLAYER NAME  YEAR  ROUNDS  AVERAGE  TOTAL SG:ARG  MEASURED ROUNDS  \\\n",
       "0     Dustin Johnson  2019      73    0.234        13.098               56   \n",
       "1           Jon Rahm  2019      75    0.073         3.863               53   \n",
       "2      Justin Thomas  2019      75    0.352        19.729               56   \n",
       "3       Rory McIlroy  2019      72    0.297        16.939               57   \n",
       "4       Webb Simpson  2019      81    0.294        20.269               69   \n",
       "..               ...   ...     ...      ...           ...              ...   \n",
       "127   Patton Kizzire  2019      76   -0.120        -6.337               53   \n",
       "128    Peter Malnati  2019      87    0.097         7.362               76   \n",
       "129  Bronson Burgoon  2019      59   -0.074        -3.481               47   \n",
       "130     Chris Stroud  2019      70    0.035         1.808               52   \n",
       "131     Roberto Díaz  2019      73    0.063         3.190               51   \n",
       "\n",
       "     ROUNDS_x  AVERAGE_x  SG:OTT  SG:APR  SG:ARG  AVERAGE_y  TOTAL SG:T  \\\n",
       "0          73      1.225   0.703   0.288   0.234      1.321      73.995   \n",
       "1          75      1.170   0.692   0.405   0.073      1.505      79.788   \n",
       "2          75      1.817   0.479   0.985   0.352      1.631      91.314   \n",
       "3          72      2.126   1.195   0.633   0.297      2.551     145.379   \n",
       "4          81      0.899  -0.007   0.613   0.294      1.507     104.007   \n",
       "..        ...        ...     ...     ...     ...        ...         ...   \n",
       "127        76     -0.740  -0.489  -0.132  -0.120     -0.098      -5.192   \n",
       "128        87     -0.088  -0.410   0.225   0.097      0.379      28.774   \n",
       "129        59     -0.053   0.054  -0.033  -0.074     -0.344     -16.148   \n",
       "130        70     -0.752  -0.557  -0.229   0.035     -0.729     -37.920   \n",
       "131        73     -0.285   0.118  -0.466   0.063     -0.123      -6.295   \n",
       "\n",
       "     TOTAL SG:T2G  TOTAL SG:P  AVERAGE_x.1  TOTAL SG:PUTTING  AVERAGE_y.1  \\\n",
       "0          68.619       5.378        0.096             5.378        0.288   \n",
       "1          61.994      17.793        0.336            17.793        0.405   \n",
       "2         101.736     -10.419       -0.186           -10.419        0.985   \n",
       "3         121.159      24.221        0.425            24.221        0.633   \n",
       "4          62.051      41.957        0.608            41.957        0.613   \n",
       "..            ...         ...          ...               ...          ...   \n",
       "127       -39.241      34.050        0.642            34.050       -0.132   \n",
       "128        -6.693      35.469        0.467            35.469        0.225   \n",
       "129        -2.469     -13.679       -0.291           -13.679       -0.033   \n",
       "130       -39.088       1.165        0.022             1.165       -0.229   \n",
       "131       -14.533       8.239        0.162             8.239       -0.466   \n",
       "\n",
       "     TOTAL SG:APP RANK AS LABEL  \n",
       "0          16.143             A  \n",
       "1          21.449             A  \n",
       "2          55.176             A  \n",
       "3          36.096             A  \n",
       "4          42.285             A  \n",
       "..            ...           ...  \n",
       "127        -6.987             F  \n",
       "128        17.084             F  \n",
       "129        -1.540             F  \n",
       "130       -11.918             F  \n",
       "131       -23.741             F  \n",
       "\n",
       "[132 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.2.2 K-Fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits()\n",
    "trainSets = []\n",
    "testSets = []\n",
    "for k in kf.split(dfRaw):\n",
    "    trainSets.append(dfRaw.iloc[k[0]])\n",
    "    testSets.append(dfRaw.iloc[k[1]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (0.3) Find Feature Names"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "featureNames = dfTrain.columns[3:-1] # Skip ID, name, year, rounds, and rank as label\n",
    "nFeatures = featureNames.shape[0]\n",
    "print(\"Number of features:\", nFeatures)\n",
    "featureNames"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features: 16\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['AVERAGE', 'TOTAL SG:ARG', 'MEASURED ROUNDS', 'ROUNDS_x', 'AVERAGE_x',\n",
       "       'SG:OTT', 'SG:APR', 'SG:ARG', 'AVERAGE_y', 'TOTAL SG:T', 'TOTAL SG:T2G',\n",
       "       'TOTAL SG:P', 'AVERAGE_x.1', 'TOTAL SG:PUTTING', 'AVERAGE_y.1',\n",
       "       'TOTAL SG:APP'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (0.4) Select Training Instances (features and values) from the Training Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "trainingInstancesList = []\n",
    "for train in trainSets:\n",
    "    trainingInstances_x = []\n",
    "    trainingInstances_y = []\n",
    "    for instance in train.to_numpy():\n",
    "        featureValues = list(instance[3:-1])\n",
    "        label = instance[-1]\n",
    "        trainingInstances_x.append(featureValues)\n",
    "        trainingInstances_y.append(label)\n",
    "    nTrainingInstances = len(trainingInstances_x)\n",
    "    trainingInstancesList.append((trainingInstances_x, trainingInstances_y, nTrainingInstances))\n",
    "    print(\"Number of training instances:\", nTrainingInstances)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training instances: 508\n",
      "Number of training instances: 509\n",
      "Number of training instances: 509\n",
      "Number of training instances: 509\n",
      "Number of training instances: 509\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (0.5) Select Test Instances from the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "testInstancesList = []\n",
    "for test in testSets:    \n",
    "    testInstances_x = []\n",
    "    testInstances_y = []\n",
    "    for instance in test.to_numpy():\n",
    "        featureValues = list(instance[3:-1])\n",
    "        label = instance[-1]\n",
    "        testInstances_x.append(featureValues)\n",
    "        testInstances_y.append(label)\n",
    "    nTrainingInstances = len(trainingInstances_x)\n",
    "    print(\"Number of training instances:\", nTrainingInstances)\n",
    "    testInstancesList.append((testInstances_x, testInstances_y, nTrainingInstances))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training instances: 509\n",
      "Number of training instances: 509\n",
      "Number of training instances: 509\n",
      "Number of training instances: 509\n",
      "Number of training instances: 509\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (0.6) MAE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def mae(testInstances, prediction):\n",
    "    for i in range(len(prediction)):\n",
    "        print('Predict: {}, Actual: {}'.format(prediction[i], testInstances[i]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Support Vector Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Linear SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "for trainingInstances, testInstances in zip(trainingInstancesList, testInstancesList):\n",
    "    trainingInstances_x = trainingInstances[0]\n",
    "    trainingInstances_y = trainingInstances[1]\n",
    "    testInstances_x = testInstances[0]\n",
    "    testInstances_y = testInstances[1]\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(trainingInstances_x, trainingInstances_y)\n",
    "    y_pred = clf.predict(testInstances_x)\n",
    "    \n",
    "    # CALCULATIONS FOR MAE\n",
    "    y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "    y_ans_as_distance = [distance_dict[a] for a in testInstances_y]\n",
    "    MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "    \n",
    "    #print(\"Predicted:\", y_pred)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    acc_sum += metrics.accuracy_score(testInstances_y, y_pred)\n",
    "    print(\"F1 Micro:\", metrics.f1_score(testInstances_y, y_pred, average='micro'))\n",
    "    f1micro_sum += metrics.f1_score(testInstances_y, y_pred, average='micro')\n",
    "    print(\"F1 Macro:\", metrics.f1_score(testInstances_y, y_pred, average='macro'))\n",
    "    f1macro_sum += metrics.f1_score(testInstances_y, y_pred, average='macro')\n",
    "    y_pred_svm = y_pred\n",
    "print(\"Overall MAE: \", MAE_sum / len(testSets))\n",
    "print(\"Overall Accuracy: \", acc_sum / len(testSets))\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / len(testSets))\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / len(testSets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.3359375\n",
      "F1 Micro: 0.3359375\n",
      "F1 Macro: 0.2640344909739624\n",
      "Accuracy: 0.2440944881889764\n",
      "F1 Micro: 0.2440944881889764\n",
      "F1 Macro: 0.17992694266806875\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.3543307086614173\n",
      "F1 Micro: 0.3543307086614173\n",
      "F1 Macro: 0.21404621154335113\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.30708661417322836\n",
      "F1 Micro: 0.30708661417322836\n",
      "F1 Macro: 0.2745427758585653\n",
      "Accuracy: 0.16535433070866143\n",
      "F1 Micro: 0.16535433070866143\n",
      "F1 Macro: 0.061995133819951344\n",
      "Overall MAE:  1.3348056102362205\n",
      "Overall Accuracy:  0.2813607283464567\n",
      "Overall F1 Micro:  0.2813607283464567\n",
      "Overall F1 Macro:  0.19890911097277977\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Kernel SVM  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kernel is Radius Basis Function: Gaussian:  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.svm import SVC\n",
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "for trainingInstances, testInstances in zip(trainingInstancesList, testInstancesList):\n",
    "    trainingInstances_x = trainingInstances[0]\n",
    "    trainingInstances_y = trainingInstances[1]\n",
    "    testInstances_x = testInstances[0]\n",
    "    testInstances_y = testInstances[1]\n",
    "    clf = SVC()\n",
    "    clf.fit(trainingInstances_x, trainingInstances_y)\n",
    "    y_pred = clf.predict(testInstances_x)\n",
    "    \n",
    "    \n",
    "    # CALCULATIONS FOR MAE\n",
    "    y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "    y_ans_as_distance = [distance_dict[a] for a in testInstances_y]\n",
    "    MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "    \n",
    "    \n",
    "    #print(\"Predicted:\", y_pred)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    acc_sum += metrics.accuracy_score(testInstances_y, y_pred)\n",
    "    print(\"F1 Micro:\", metrics.f1_score(testInstances_y, y_pred, average='micro'))\n",
    "    f1micro_sum += metrics.f1_score(testInstances_y, y_pred, average='micro')\n",
    "    print(\"F1 Macro:\", metrics.f1_score(testInstances_y, y_pred, average='macro'))\n",
    "    f1macro_sum += metrics.f1_score(testInstances_y, y_pred, average='macro')\n",
    "    y_pred_svm = y_pred\n",
    "print(\"Overall MAE: \", MAE_sum / len(testSets))\n",
    "print(\"Overall Accuracy: \", acc_sum / len(testSets))\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / len(testSets))\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / len(testSets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.359375\n",
      "F1 Micro: 0.359375\n",
      "F1 Macro: 0.2347613248322468\n",
      "Accuracy: 0.3700787401574803\n",
      "F1 Micro: 0.37007874015748027\n",
      "F1 Macro: 0.279578452400594\n",
      "Accuracy: 0.3700787401574803\n",
      "F1 Micro: 0.37007874015748027\n",
      "F1 Macro: 0.24412487154422638\n",
      "Accuracy: 0.3937007874015748\n",
      "F1 Micro: 0.39370078740157477\n",
      "F1 Macro: 0.2923057157246667\n",
      "Accuracy: 0.4330708661417323\n",
      "F1 Micro: 0.4330708661417323\n",
      "F1 Macro: 0.31790754591825066\n",
      "Overall MAE:  0.9841781496062992\n",
      "Overall Accuracy:  0.3852608267716535\n",
      "Overall F1 Micro:  0.3852608267716535\n",
      "Overall F1 Macro:  0.27373558208399684\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kernel is Quadratic kernel (\"Degree-2 polynomial kernel\"):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "for trainingInstances, testInstances in zip(trainingInstancesList, testInstancesList):\n",
    "    trainingInstances_x = trainingInstances[0]\n",
    "    trainingInstances_y = trainingInstances[1]\n",
    "    testInstances_x = testInstances[0]\n",
    "    testInstances_y = testInstances[1]\n",
    "    clf = SVC(kernel='poly', degree=2)\n",
    "    clf.fit(trainingInstances_x, trainingInstances_y)\n",
    "    y_pred = clf.predict(testInstances_x)\n",
    "    \n",
    "    # CALCULATIONS FOR MAE\n",
    "    y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "    y_ans_as_distance = [distance_dict[a] for a in testInstances_y]\n",
    "    MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "    \n",
    "    #print(\"Predicted:\", y_pred)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    acc_sum += metrics.accuracy_score(testInstances_y, y_pred)\n",
    "    print(\"F1 Micro:\", metrics.f1_score(testInstances_y, y_pred, average='micro'))\n",
    "    f1micro_sum += metrics.f1_score(testInstances_y, y_pred, average='micro')\n",
    "    print(\"F1 Macro:\", metrics.f1_score(testInstances_y, y_pred, average='macro'))\n",
    "    f1macro_sum += metrics.f1_score(testInstances_y, y_pred, average='macro')\n",
    "    y_pred_svm = y_pred\n",
    "print(\"Overall MAE: \", MAE_sum / len(testSets))\n",
    "print(\"Overall Accuracy: \", acc_sum / len(testSets))\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / len(testSets))\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / len(testSets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.3515625\n",
      "F1 Micro: 0.3515625\n",
      "F1 Macro: 0.24140211640211642\n",
      "Accuracy: 0.3779527559055118\n",
      "F1 Micro: 0.37795275590551175\n",
      "F1 Macro: 0.2554452715743038\n",
      "Accuracy: 0.36220472440944884\n",
      "F1 Micro: 0.36220472440944884\n",
      "F1 Macro: 0.23462213070998247\n",
      "Accuracy: 0.4015748031496063\n",
      "F1 Micro: 0.4015748031496063\n",
      "F1 Macro: 0.2950817904977498\n",
      "Accuracy: 0.4015748031496063\n",
      "F1 Micro: 0.4015748031496063\n",
      "F1 Macro: 0.28425925925925927\n",
      "Overall MAE:  0.9810162401574803\n",
      "Overall Accuracy:  0.37897391732283464\n",
      "Overall F1 Micro:  0.37897391732283464\n",
      "Overall F1 Macro:  0.26216211368868236\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training KNN Classifiers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# KNN WITH n_neighbors=5\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "for trainingInstances, testInstances in zip(trainingInstancesList, testInstancesList):\n",
    "    trainingInstances_x = trainingInstances[0]\n",
    "    trainingInstances_y = trainingInstances[1]\n",
    "    testInstances_x = testInstances[0]\n",
    "    testInstances_y = testInstances[1]\n",
    "    clf = KNeighborsClassifier() # n_neighbors=5\n",
    "    clf.fit(trainingInstances_x, trainingInstances_y)\n",
    "    y_pred = clf.predict(testInstances_x)\n",
    "    #print(\"Predicted:\", y_pred)\n",
    "    \n",
    "    # CALCULATIONS FOR MAE\n",
    "    y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "    y_ans_as_distance = [distance_dict[a] for a in testInstances_y]\n",
    "    MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "    \n",
    "    print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    acc_sum += metrics.accuracy_score(testInstances_y, y_pred)\n",
    "    print(\"F1 Micro:\", metrics.f1_score(testInstances_y, y_pred, average='micro'))\n",
    "    f1micro_sum += metrics.f1_score(testInstances_y, y_pred, average='micro')\n",
    "    print(\"F1 Macro:\", metrics.f1_score(testInstances_y, y_pred, average='macro'))\n",
    "    f1macro_sum += metrics.f1_score(testInstances_y, y_pred, average='macro')\n",
    "    y_pred_svm = y_pred\n",
    "print(\"Overall MAE: \", MAE_sum / len(testSets))\n",
    "print(\"Overall Accuracy: \", acc_sum / len(testSets))\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / len(testSets))\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / len(testSets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.359375\n",
      "F1 Micro: 0.359375\n",
      "F1 Macro: 0.2994049411393585\n",
      "Accuracy: 0.3779527559055118\n",
      "F1 Micro: 0.37795275590551175\n",
      "F1 Macro: 0.3488184255884705\n",
      "Accuracy: 0.4015748031496063\n",
      "F1 Micro: 0.4015748031496063\n",
      "F1 Macro: 0.36140942346501886\n",
      "Accuracy: 0.3779527559055118\n",
      "F1 Micro: 0.37795275590551175\n",
      "F1 Macro: 0.3535038928871946\n",
      "Accuracy: 0.33858267716535434\n",
      "F1 Micro: 0.33858267716535434\n",
      "F1 Macro: 0.30488824823689864\n",
      "Overall MAE:  1.050369094488189\n",
      "Overall Accuracy:  0.37108759842519684\n",
      "Overall F1 Micro:  0.37108759842519684\n",
      "Overall F1 Macro:  0.3336049862633882\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# KNN WITH n_neighbors=3\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "for trainingInstances, testInstances in zip(trainingInstancesList, testInstancesList):\n",
    "    trainingInstances_x = trainingInstances[0]\n",
    "    trainingInstances_y = trainingInstances[1]\n",
    "    testInstances_x = testInstances[0]\n",
    "    testInstances_y = testInstances[1]\n",
    "    clf = KNeighborsClassifier(n_neighbors=3) # n_neighbors = 3\n",
    "    clf.fit(trainingInstances_x, trainingInstances_y)\n",
    "    y_pred = clf.predict(testInstances_x)\n",
    "    #print(\"Predicted:\", y_pred)\n",
    "\n",
    "    # CALCULATIONS FOR MAE\n",
    "    y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "    y_ans_as_distance = [distance_dict[a] for a in testInstances_y]\n",
    "    MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "    \n",
    "    print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    acc_sum += metrics.accuracy_score(testInstances_y, y_pred)\n",
    "    print(\"F1 Micro:\", metrics.f1_score(testInstances_y, y_pred, average='micro'))\n",
    "    f1micro_sum += metrics.f1_score(testInstances_y, y_pred, average='micro')\n",
    "    print(\"F1 Macro:\", metrics.f1_score(testInstances_y, y_pred, average='macro'))\n",
    "    f1macro_sum += metrics.f1_score(testInstances_y, y_pred, average='macro')\n",
    "    y_pred_svm = y_pred\n",
    "print(\"Overall MAE: \", MAE_sum / len(testSets))\n",
    "print(\"Overall Accuracy: \", acc_sum / len(testSets))\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / len(testSets))\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / len(testSets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.3125\n",
      "F1 Micro: 0.3125\n",
      "F1 Macro: 0.2734259649557016\n",
      "Accuracy: 0.3543307086614173\n",
      "F1 Micro: 0.3543307086614173\n",
      "F1 Macro: 0.3410830999066293\n",
      "Accuracy: 0.30708661417322836\n",
      "F1 Micro: 0.30708661417322836\n",
      "F1 Macro: 0.28332082551594745\n",
      "Accuracy: 0.29133858267716534\n",
      "F1 Micro: 0.29133858267716534\n",
      "F1 Macro: 0.2975182556649522\n",
      "Accuracy: 0.25984251968503935\n",
      "F1 Micro: 0.25984251968503935\n",
      "F1 Macro: 0.2466221777542853\n",
      "Overall MAE:  1.25625\n",
      "Overall Accuracy:  0.3050196850393701\n",
      "Overall F1 Micro:  0.3050196850393701\n",
      "Overall F1 Macro:  0.2883940647595032\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Gaussian Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "for trainingInstances, testInstances in zip(trainingInstancesList, testInstancesList):\n",
    "    trainingInstances_x = trainingInstances[0]\n",
    "    trainingInstances_y = trainingInstances[1]\n",
    "    testInstances_x = testInstances[0]\n",
    "    testInstances_y = testInstances[1]\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(trainingInstances_x, trainingInstances_y)\n",
    "    y_pred = clf.predict(testInstances_x)\n",
    "    #print(\"Predicted:\"print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    \n",
    "    # CALCULATIONS FOR MAE\n",
    "    y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "    y_ans_as_distance = [distance_dict[a] for a in testInstances_y]\n",
    "    MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "    \n",
    "    print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    acc_sum += metrics.accuracy_score(testInstances_y, y_pred)\n",
    "    print(\"F1 Micro:\", metrics.f1_score(testInstances_y, y_pred, average='micro'))\n",
    "    f1micro_sum += metrics.f1_score(testInstances_y, y_pred, average='micro')\n",
    "    print(\"F1 Macro:\", metrics.f1_score(testInstances_y, y_pred, average='macro'))\n",
    "    f1macro_sum += metrics.f1_score(testInstances_y, y_pred, average='macro')\n",
    "    y_pred_svm = y_pred\n",
    "print(\"Overall MAE: \", MAE_sum / len(testSets))\n",
    "print(\"Overall Accuracy: \", acc_sum / len(testSets))\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / len(testSets))\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / len(testSets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.390625\n",
      "F1 Micro: 0.390625\n",
      "F1 Macro: 0.34375385836493527\n",
      "Accuracy: 0.3228346456692913\n",
      "F1 Micro: 0.3228346456692913\n",
      "F1 Macro: 0.29949546039239194\n",
      "Accuracy: 0.36220472440944884\n",
      "F1 Micro: 0.36220472440944884\n",
      "F1 Macro: 0.3105789471380869\n",
      "Accuracy: 0.4015748031496063\n",
      "F1 Micro: 0.4015748031496063\n",
      "F1 Macro: 0.41277586701315516\n",
      "Accuracy: 0.2992125984251969\n",
      "F1 Micro: 0.2992125984251969\n",
      "F1 Macro: 0.2920152496125799\n",
      "Overall MAE:  1.014271653543307\n",
      "Overall Accuracy:  0.3552903543307087\n",
      "Overall F1 Micro:  0.3552903543307087\n",
      "Overall F1 Macro:  0.3317238765042298\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Naive Solution - Random Guess"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import random\n",
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "representative_sample = [\"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"D\", \"D\", \"D\", \"D\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\",\n",
    "                        \"E\", \"F\",\"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\"]\n",
    "\n",
    "for trainingInstances, testInstances in zip(trainingInstancesList, testInstancesList):\n",
    "    trainingInstances_x = trainingInstances[0]\n",
    "    trainingInstances_y = trainingInstances[1]\n",
    "    testInstances_x = testInstances[0]\n",
    "    testInstances_y = testInstances[1]\n",
    "    y_pred = [random.sample(representative_sample, 1)[0] for y in testInstances_y]\n",
    "    \n",
    "    # CALCULATIONS FOR MAE\n",
    "    y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "    y_ans_as_distance = [distance_dict[a] for a in testInstances_y]\n",
    "    MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "    \n",
    "    print(\"Accuracy:\", metrics.accuracy_score(testInstances_y, y_pred))\n",
    "    acc_sum += metrics.accuracy_score(testInstances_y, y_pred)\n",
    "    print(\"F1 Micro:\", metrics.f1_score(testInstances_y, y_pred, average='micro'))\n",
    "    f1micro_sum += metrics.f1_score(testInstances_y, y_pred, average='micro')\n",
    "    print(\"F1 Macro:\", metrics.f1_score(testInstances_y, y_pred, average='macro'))\n",
    "    f1macro_sum += metrics.f1_score(testInstances_y, y_pred, average='macro')\n",
    "    y_pred_svm = y_pred\n",
    "print(\"Overall MAE: \", MAE_sum / len(testSets))\n",
    "print(\"Overall Accuracy: \", acc_sum / len(testSets))\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / len(testSets))\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / len(testSets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.265625\n",
      "F1 Micro: 0.265625\n",
      "F1 Macro: 0.17670034758642353\n",
      "Accuracy: 0.16535433070866143\n",
      "F1 Micro: 0.16535433070866143\n",
      "F1 Macro: 0.11834247492849644\n",
      "Accuracy: 0.2283464566929134\n",
      "F1 Micro: 0.2283464566929134\n",
      "F1 Macro: 0.17840993167080124\n",
      "Accuracy: 0.2125984251968504\n",
      "F1 Micro: 0.2125984251968504\n",
      "F1 Macro: 0.16328229915473016\n",
      "Accuracy: 0.2283464566929134\n",
      "F1 Micro: 0.2283464566929134\n",
      "F1 Macro: 0.1688551483536602\n",
      "Overall MAE:  1.8589566929133858\n",
      "Overall Accuracy:  0.22005413385826772\n",
      "Overall F1 Micro:  0.22005413385826772\n",
      "Overall F1 Macro:  0.16111804033882232\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Naive Solution - Use Last Year's Rank"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def convert_rank_to_class(raw_ans):\n",
    "    ans = \"\"\n",
    "    if raw_ans < 21:\n",
    "        ans = \"A\"\n",
    "    elif raw_ans < 41:\n",
    "        ans = \"B\"\n",
    "    elif raw_ans < 61:\n",
    "        ans = \"C\"\n",
    "    elif raw_ans < 101:\n",
    "        ans = \"D\"\n",
    "    elif raw_ans < 201:\n",
    "        ans = \"E\"\n",
    "    else:\n",
    "        ans = \"F\"\n",
    "    return ans\n",
    "\n",
    "\n",
    "import random\n",
    "acc_sum = 0\n",
    "f1micro_sum = 0\n",
    "f1macro_sum = 0\n",
    "MAE_sum = 0\n",
    "\n",
    "main_data = pd.read_csv(\"../data/combined.csv\")\n",
    "df_continuity = pd.read_csv(\"../owgr_2004-2019.csv\")\n",
    "\n",
    "y_pred = []\n",
    "y_ans = []\n",
    "\n",
    "# run predictions from 2004 to 2019 (using players in main_data)\n",
    "for index, row in main_data[main_data['year'] >= 2004 & main_data['year'] <= 2019].iterrows():\n",
    "    player = (df_continuity['name'] == row['name']) & (df_continuity['year'] == row['year'])\n",
    "    player_ranking_data = df_continuity.loc[player]\n",
    "\n",
    "    current_rank = player_ranking_data['current_rank'].values[0]\n",
    "    rank_year_plus_two = player_ranking_data['rank_year_plus_two'].values[0]\n",
    "\n",
    "    if rank_year_plus_two > 300:\n",
    "        continue\n",
    "\n",
    "    guess_instance = convert_rank_to_class(current_rank)\n",
    "    ans_instance = convert_rank_to_class(rank_year_plus_two)\n",
    "\n",
    "    y_pred.append(guess_instance)\n",
    "    y_ans.append(ans_instance)\n",
    "\n",
    "print(len(y_pred))\n",
    "print(len(y_ans))\n",
    "\n",
    "# CALCULATIONS FOR MAE\n",
    "y_pred_as_distance = [distance_dict[a] for a in y_pred]\n",
    "y_ans_as_distance = [distance_dict[a] for a in y_ans]\n",
    "MAE_sum += metrics.mean_absolute_error(y_ans_as_distance, y_pred_as_distance)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_ans, y_pred))\n",
    "acc_sum += metrics.accuracy_score(y_ans, y_pred)\n",
    "print(\"F1 Micro:\", metrics.f1_score(y_ans, y_pred, average='micro'))\n",
    "f1micro_sum += metrics.f1_score(y_ans, y_pred, average='micro')\n",
    "print(\"F1 Macro:\", metrics.f1_score(y_ans, y_pred, average='macro'))\n",
    "f1macro_sum += metrics.f1_score(y_ans, y_pred, average='macro')\n",
    "\n",
    "print(\"Overall MAE: \", MAE_sum / 1)\n",
    "print(\"Overall Accuracy: \", acc_sum / 1)\n",
    "print(\"Overall F1 Micro: \", f1micro_sum / 1)\n",
    "print(\"Overall F1 Macro: \", f1macro_sum / 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1683\n",
      "1683\n",
      "Accuracy: 0.3196672608437314\n",
      "F1 Micro: 0.3196672608437314\n",
      "F1 Macro: 0.307310147545276\n",
      "Overall MAE:  1.1354723707664884\n",
      "Overall Accuracy:  0.3196672608437314\n",
      "Overall F1 Micro:  0.3196672608437314\n",
      "Overall F1 Macro:  0.307310147545276\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}